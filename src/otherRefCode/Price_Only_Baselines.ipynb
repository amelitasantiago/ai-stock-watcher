{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Price-Only Baselines (5y) \u2014 AI Stock Watcher\n",
        "\n",
        "This notebook trains **price-only** baselines using the 5-year adjusted close panel (`adj_close_wide.parquet`).\n",
        "We start simple and strong:\n",
        "\n",
        "1. **Naive-1** baseline: predict next-day return = last return.\n",
        "2. **Ridge (lagged returns)** baseline: predict next-day return using the last *L* days of returns.\n",
        "3. *(Optional)* **ARIMA** quick baseline for comparison.\n",
        "\n",
        "Outputs:\n",
        "- `artifacts/price_only_ridge.joblib` \u2014 StandardScaler+Ridge pipeline\n",
        "- `artifacts/price_only_meta.json` \u2014 feature/ticker metadata\n",
        "- `artifacts/arima_<TICKER>.pkl` (optional)\n",
        "\n",
        "**Usage**: Upload or mount your `adj_close_wide.parquet` and set the input path below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 0) Setup\n",
        "!pip -q install pandas pyarrow scikit-learn statsmodels joblib matplotlib --upgrade\n",
        "import pandas as pd, numpy as np, json, os, math\n",
        "from pathlib import Path\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "print('Setup complete.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 1) Input paths and parameters\n",
        "ADJ_CLOSE_WIDE = \"/content/drive/MyDrive/ai_stock_watcher/data/curated/adj_close_wide.parquet\"  #@param {type:\"string\"}\n",
        "TARGET_TICKER = \"AAPL\"  #@param {type:\"string\"}\n",
        "LAGS = 20  #@param {type:\"integer\"}\n",
        "TEST_SPLIT_FRACTION = 0.2  #@param {type:\"number\"}\n",
        "ART_DIR = \"/content/drive/MyDrive/ai_stock_watcher/artifacts\"  #@param {type:\"string\"}\n",
        "\n",
        "Path(ART_DIR).mkdir(parents=True, exist_ok=True)\n",
        "print('ART_DIR =', ART_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 2) Load 5y panel and compute returns\n",
        "prices = pd.read_parquet(ADJ_CLOSE_WIDE)\n",
        "prices = prices.sort_index().asfreq('B')  # business days\n",
        "if TARGET_TICKER not in prices.columns:\n",
        "    raise ValueError(f\"{TARGET_TICKER} not found in adj_close_wide.parquet columns.\")\n",
        "\n",
        "# simple returns (you can switch to log returns if you prefer)\n",
        "rets = prices.pct_change()\n",
        "target = rets[[TARGET_TICKER]].rename(columns={TARGET_TICKER: 'y'})\n",
        "display(target.tail())\n",
        "print('Data points:', len(target), 'Date range:', target.index.min(), '\u2192', target.index.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 3) Build lagged-return features\n",
        "def make_lagged_features(y: pd.Series, lags: int) -> pd.DataFrame:\n",
        "    df = pd.DataFrame({\"y\": y})\n",
        "    for k in range(1, lags+1):\n",
        "        df[f\"lag_{k}\"] = df['y'].shift(k)\n",
        "    # Drop first 'lags' rows with NaNs\n",
        "    return df.dropna()\n",
        "\n",
        "df = make_lagged_features(target['y'], LAGS)\n",
        "X = df.filter(like='lag_')\n",
        "y = df['y'].shift(-1).dropna()  # predict next-day return\n",
        "X = X.iloc[:-1]\n",
        "assert len(X) == len(y)\n",
        "display(df.tail())\n",
        "print('Feature matrix:', X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 4) Train/validation split (time-based)\n",
        "split = int(len(X) * (1 - TEST_SPLIT_FRACTION))\n",
        "X_train, X_test = X.iloc[:split], X.iloc[split:]\n",
        "y_train, y_test = y.iloc[:split], y.iloc[split:]\n",
        "print('Train:', X_train.shape, 'Test:', X_test.shape)\n",
        "\n",
        "# Naive-1 baseline: predict next = last return\n",
        "yhat_naive = X_test['lag_1'].values\n",
        "rmse_naive = mean_squared_error(y_test, yhat_naive, squared=False)\n",
        "mae_naive = mean_absolute_error(y_test, yhat_naive)\n",
        "dir_acc_naive = (np.sign(yhat_naive) == np.sign(y_test.values)).mean()\n",
        "print(f\"Naive-1 \u2192 RMSE={rmse_naive:.6f}  MAE={mae_naive:.6f}  DirAcc={dir_acc_naive:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 5) Ridge baseline (StandardScaler + Ridge)\n",
        "pipe = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"ridge\", Ridge(alpha=1.0, random_state=42))\n",
        "])\n",
        "pipe.fit(X_train, y_train)\n",
        "yhat = pipe.predict(X_test)\n",
        "\n",
        "rmse = mean_squared_error(y_test, yhat, squared=False)\n",
        "mae = mean_absolute_error(y_test, yhat)\n",
        "dir_acc = (np.sign(yhat) == np.sign(y_test.values)).mean()\n",
        "print(f\"Ridge \u2192 RMSE={rmse:.6f}  MAE={mae:.6f}  DirAcc={dir_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 6) Plot: actual vs predicted returns (test set)\n",
        "plt.figure()\n",
        "plt.plot(y_test.index, y_test.values, label='Actual')\n",
        "plt.plot(y_test.index, yhat, label='Predicted')\n",
        "plt.title(f\"{TARGET_TICKER} \u2014 Returns (test set)\")\n",
        "plt.legend()\n",
        "plt.xlabel('Date'); plt.ylabel('Daily return')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 7) (Optional) ARIMA quick baseline\n",
        "USE_ARIMA = False  #@param {type:\"boolean\"}\n",
        "ARIMA_ORDER = (1,1,1)  #@param {type:\"raw\"}\n",
        "if USE_ARIMA:\n",
        "    import warnings\n",
        "    warnings.filterwarnings('ignore')\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    p = prices[TARGET_TICKER].dropna()\n",
        "    p = p.loc[X_train.index.min():X_test.index.max()]\n",
        "    p_train = p.loc[:X_train.index.max()]\n",
        "    p_test = p.loc[X_test.index.min():]\n",
        "    model = ARIMA(p_train, order=ARIMA_ORDER)\n",
        "    res = model.fit()\n",
        "    fc = res.forecast(steps=len(p_test))\n",
        "    fc_ret = fc.pct_change().reindex(y_test.index).fillna(0.0)\n",
        "    rmse_a = mean_squared_error(y_test, fc_ret, squared=False)\n",
        "    mae_a = mean_absolute_error(y_test, fc_ret)\n",
        "    dir_acc_a = (np.sign(fc_ret.values) == np.sign(y_test.values)).mean()\n",
        "    print(f\"ARIMA{ARIMA_ORDER} \u2192 RMSE={rmse_a:.6f}  MAE={mae_a:.6f}  DirAcc={dir_acc_a:.3f}\")\n",
        "    import pickle, os\n",
        "    with open(os.path.join(ART_DIR, f\"arima_{TARGET_TICKER}.pkl\"), 'wb') as f:\n",
        "        pickle.dump(res, f)\n",
        "    print('Saved ARIMA model:', os.path.join(ART_DIR, f\"arima_{TARGET_TICKER}.pkl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 8) Save artifacts (pipeline + metadata)\n",
        "pipe_path = os.path.join(ART_DIR, \"price_only_ridge.joblib\")\n",
        "joblib.dump(pipe, pipe_path)\n",
        "meta = {\n",
        "    \"ticker\": TARGET_TICKER,\n",
        "    \"lags\": int(LAGS),\n",
        "    \"features\": list(X.columns),\n",
        "    \"metrics\": {\n",
        "        \"ridge\": {\"rmse\": float(rmse), \"mae\": float(mae), \"dir_acc\": float(dir_acc)},\n",
        "        \"naive1\": {\"rmse\": float(rmse_naive), \"mae\": float(mae_naive), \"dir_acc\": float(dir_acc_naive)}\n",
        "    }\n",
        "}\n",
        "with open(os.path.join(ART_DIR, \"price_only_meta.json\"), 'w') as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print('Saved pipeline \u2192', pipe_path)\n",
        "print('Saved meta \u2192', os.path.join(ART_DIR, 'price_only_meta.json'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 9) Local inference helper (Ridge) \u2014 price-only\n",
        "import json, joblib, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def load_price_only(art_dir:str):\n",
        "    pipe = joblib.load(os.path.join(art_dir, 'price_only_ridge.joblib'))\n",
        "    meta = json.loads(Path(os.path.join(art_dir, 'price_only_meta.json')).read_text())\n",
        "    return pipe, meta\n",
        "\n",
        "def build_window_from_series(returns: pd.Series, lags:int) -> pd.DataFrame:\n",
        "    row = {f'lag_{k}': returns.iloc[-k] for k in range(1, lags+1)}\n",
        "    return pd.DataFrame([row])\n",
        "\n",
        "# Example usage (requires a returns series for TARGET_TICKER):\n",
        "# pipe, meta = load_price_only(ART_DIR)\n",
        "# latest_window = build_window_from_series(rets[TARGET_TICKER].dropna(), meta['lags'])\n",
        "# pred_next_ret = pipe.predict(latest_window)[0]\n",
        "# print('Predicted next-day return:', float(pred_next_ret))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
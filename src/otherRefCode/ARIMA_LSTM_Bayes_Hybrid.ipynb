{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ARIMA, LSTM, and Bayesian Ridge \u2014 with Hybrid LSTM+Transformer Features\n",
        "\n",
        "This notebook trains three forecasters on a single target ticker:\n",
        "\n",
        "1. **ARIMA / SARIMAX** (classical)\n",
        "2. **LSTM** (sequence model)\n",
        "3. **Bayesian Ridge** with **hybrid features** from **LSTM** and a **Transformer Encoder**\n",
        "\n",
        "**Data**: `adj_close_wide.parquet` (5 years of daily adjusted close, wide by ticker). We model **next-day return**.\n",
        "\n",
        "Outputs:\n",
        "- `artifacts/lstm_savedmodel` \u2014 Keras LSTM forecaster\n",
        "- `artifacts/transformer_savedmodel` \u2014 Keras Transformer forecaster (used for embeddings)\n",
        "- `artifacts/bayes_hybrid.joblib` \u2014 Bayesian Ridge on hybrid embeddings (+ optional lag features)\n",
        "- `artifacts/sarimax.pkl` \u2014 SARIMAX with exogenous hybrid features\n",
        "- `artifacts/meta.json` \u2014 parameters & metrics\n",
        "\n",
        "You can later use these artifacts in your local UI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 0) Setup\n",
        "!pip -q install pandas pyarrow numpy scikit-learn statsmodels joblib tensorflow matplotlib --upgrade\n",
        "import os, json, math, pickle\n",
        "import numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "print('Setup complete. TF:', tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 1) Paths and parameters\n",
        "ADJ_CLOSE_WIDE = \"/content/drive/MyDrive/ai_stock_watcher/data/curated/adj_close_wide.parquet\"  #@param {type:\"string\"}\n",
        "TARGET_TICKER = \"AAPL\"  #@param {type:\"string\"}\n",
        "WINDOW = 90  #@param {type:\"integer\"}\n",
        "TEST_SPLIT_FRACTION = 0.2  #@param {type:\"number\"}\n",
        "ART_DIR = \"/content/drive/MyDrive/ai_stock_watcher/artifacts\"  #@param {type:\"string\"}\n",
        "Path(ART_DIR).mkdir(parents=True, exist_ok=True)\n",
        "print('ART_DIR =', ART_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 2) Load prices and create returns\n",
        "prices = pd.read_parquet(ADJ_CLOSE_WIDE).sort_index().asfreq('B')\n",
        "if TARGET_TICKER not in prices.columns:\n",
        "    raise SystemExit(f\"{TARGET_TICKER} not found in columns. Available: {list(prices.columns)[:6]} ...\")\n",
        "ret = prices[TARGET_TICKER].pct_change().dropna()\n",
        "display(ret.tail())\n",
        "print('Date range:', ret.index.min(), '\u2192', ret.index.max(), 'rows=', len(ret))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 3) Window the series \u2192 supervised dataset (WINDOW \u2192 predict next return)\n",
        "def make_windows(series: pd.Series, window: int):\n",
        "    s = series.values.astype('float32')\n",
        "    X, y, idx_end = [], [], []\n",
        "    for i in range(window, len(s)):\n",
        "        X.append(s[i-window:i])     # window ending at time i-1\n",
        "        y.append(s[i])              # predict return at time i (next day)\n",
        "        idx_end.append(series.index[i-1])  # index of the window end (aligns exog later)\n",
        "    X = np.stack(X)\n",
        "    y = np.array(y, dtype='float32')\n",
        "    idx_end = pd.to_datetime(idx_end)\n",
        "    return X, y, idx_end\n",
        "\n",
        "raw_X, raw_y, idx_end = make_windows(ret, WINDOW)\n",
        "print('Raw window tensor:', raw_X.shape, 'targets:', raw_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 4) Train/val/test split (time-based) and scaling\n",
        "n = len(raw_X)\n",
        "n_train = int(n * (1 - TEST_SPLIT_FRACTION))\n",
        "n_val = int(n_train * 0.1)  # 10% of train for validation\n",
        "n_train_final = n_train - n_val\n",
        "\n",
        "X_train, y_train = raw_X[:n_train_final], raw_y[:n_train_final]\n",
        "X_val, y_val     = raw_X[n_train_final:n_train], raw_y[n_train_final:n_train]\n",
        "X_test, y_test   = raw_X[n_train:], raw_y[n_train:]\n",
        "idx_end_train    = idx_end[:n_train]\n",
        "idx_end_test     = idx_end[n_train:]\n",
        "\n",
        "# Scale returns using train stats, apply to all windows\n",
        "sc = StandardScaler()\n",
        "sc.fit(X_train.reshape(len(X_train), -1))\n",
        "def scale_windows(X):\n",
        "    shp = X.shape\n",
        "    X2 = sc.transform(X.reshape(len(X), -1)).reshape(shp)\n",
        "    return X2\n",
        "\n",
        "Xs_train = scale_windows(X_train)\n",
        "Xs_val   = scale_windows(X_val)\n",
        "Xs_test  = scale_windows(X_test)\n",
        "print('Splits:', Xs_train.shape, Xs_val.shape, Xs_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 5) LSTM forecaster\n",
        "tf.random.set_seed(42)\n",
        "inputs = keras.Input(shape=(WINDOW, 1))\n",
        "x = layers.LSTM(64, return_sequences=True, name='lstm1')(inputs)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = layers.LSTM(32, name='lstm2')(x)\n",
        "emb_lstm = layers.Dense(32, activation='tanh', name='lstm_embedding')(x)  # embedding for hybrid features\n",
        "out = layers.Dense(1, name='out')(emb_lstm)\n",
        "lstm_model = keras.Model(inputs, out, name='lstm_forecaster')\n",
        "lstm_model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
        "\n",
        "hist = lstm_model.fit(\n",
        "    Xs_train[..., None], y_train,\n",
        "    validation_data=(Xs_val[..., None], y_val),\n",
        "    epochs=8, batch_size=32, verbose=1,\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
        ")\n",
        "yhat_lstm = lstm_model.predict(Xs_test[..., None], verbose=0).ravel()\n",
        "rmse_lstm = mean_squared_error(y_test, yhat_lstm, squared=False)\n",
        "mae_lstm  = mean_absolute_error(y_test, yhat_lstm)\n",
        "dir_lstm  = (np.sign(yhat_lstm) == np.sign(y_test)).mean()\n",
        "print(f\"LSTM \u2192 RMSE={rmse_lstm:.6f}  MAE={mae_lstm:.6f}  DirAcc={dir_lstm:.3f}\")\n",
        "\n",
        "# Save LSTM\n",
        "lstm_path = os.path.join(ART_DIR, 'lstm_savedmodel')\n",
        "lstm_model.save(lstm_path)\n",
        "print('Saved LSTM:', lstm_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 6) Transformer forecaster (for embeddings)\n",
        "def positional_encoding(length, d_model):\n",
        "    pos = np.arange(length)[:, None]\n",
        "    i = np.arange(d_model)[None, :]\n",
        "    angle_rates = 1 / np.power(10000, (2*(i//2))/np.float32(d_model))\n",
        "    angle_rads = pos * angle_rates\n",
        "    sines = np.sin(angle_rads[:, 0::2])\n",
        "    cosines = np.cos(angle_rads[:, 1::2])\n",
        "    pe = np.zeros((length, d_model))\n",
        "    pe[:, 0::2] = sines\n",
        "    pe[:, 1::2] = cosines\n",
        "    return tf.constant(pe, dtype=tf.float32)\n",
        "\n",
        "class AddPositionalEncoding(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "    def build(self, input_shape):\n",
        "        self.len = input_shape[1]\n",
        "        self.d_model = input_shape[2]\n",
        "        self.pe = positional_encoding(self.len, self.d_model)\n",
        "    def call(self, x):\n",
        "        return x + self.pe\n",
        "\n",
        "def transformer_block(x, num_heads=2, dff=64, dropout=0.1):\n",
        "    # Layer norm + MHA\n",
        "    attn_in = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    attn_out = layers.MultiHeadAttention(num_heads=num_heads, key_dim=x.shape[-1])(attn_in, attn_in)\n",
        "    x = layers.Add()([x, layers.Dropout(dropout)(attn_out)])\n",
        "    # FFN\n",
        "    ffn_in = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    ffn_out = layers.Dense(dff, activation='relu')(ffn_in)\n",
        "    ffn_out = layers.Dense(x.shape[-1])(ffn_out)\n",
        "    x = layers.Add()([x, layers.Dropout(dropout)(ffn_out)])\n",
        "    return x\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "tin = keras.Input(shape=(WINDOW, 1))\n",
        "x = layers.Dense(32)(tin)  # project to model dim\n",
        "x = AddPositionalEncoding()(x)\n",
        "x = transformer_block(x, num_heads=2, dff=64, dropout=0.1)\n",
        "x = transformer_block(x, num_heads=2, dff=64, dropout=0.1)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "emb_tr = layers.Dense(32, activation='tanh', name='tr_embedding')(x)  # embedding for hybrid features\n",
        "tout = layers.Dense(1, name='out')(emb_tr)\n",
        "tr_model = keras.Model(tin, tout, name='transformer_forecaster')\n",
        "tr_model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
        "\n",
        "hist2 = tr_model.fit(\n",
        "    Xs_train[..., None], y_train,\n",
        "    validation_data=(Xs_val[..., None], y_val),\n",
        "    epochs=8, batch_size=32, verbose=1,\n",
        "    callbacks=[keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]\n",
        ")\n",
        "yhat_tr = tr_model.predict(Xs_test[..., None], verbose=0).ravel()\n",
        "rmse_tr = mean_squared_error(y_test, yhat_tr, squared=False)\n",
        "mae_tr  = mean_absolute_error(y_test, yhat_tr)\n",
        "dir_tr  = (np.sign(yhat_tr) == np.sign(y_test)).mean()\n",
        "print(f\"Transformer \u2192 RMSE={rmse_tr:.6f}  MAE={mae_tr:.6f}  DirAcc={dir_tr:.3f}\")\n",
        "\n",
        "# Save Transformer\n",
        "tr_path = os.path.join(ART_DIR, 'transformer_savedmodel')\n",
        "tr_model.save(tr_path)\n",
        "print('Saved Transformer:', tr_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 7) Extract hybrid embeddings for all samples\n",
        "lstm_embedder = keras.Model(lstm_model.input, lstm_model.get_layer('lstm_embedding').output)\n",
        "tr_embedder   = keras.Model(tr_model.input,   tr_model.get_layer('tr_embedding').output)\n",
        "\n",
        "def embed_all(Xs):\n",
        "    e1 = lstm_embedder.predict(Xs[..., None], verbose=0)\n",
        "    e2 = tr_embedder.predict(Xs[..., None],   verbose=0)\n",
        "    return e1, e2\n",
        "\n",
        "e1_train, e2_train = embed_all(Xs_train)\n",
        "e1_val,   e2_val   = embed_all(Xs_val)\n",
        "e1_test,  e2_test  = embed_all(Xs_test)\n",
        "\n",
        "# Concatenate embeddings (+ optional last k raw lags as features)\n",
        "def last_k_lags(Xs, k=10):\n",
        "    return Xs[:, -k:]\n",
        "\n",
        "lag_k = 10\n",
        "lag_trn = last_k_lags(Xs_train, lag_k)\n",
        "lag_val = last_k_lags(Xs_val,   lag_k)\n",
        "lag_tst = last_k_lags(Xs_test,  lag_k)\n",
        "\n",
        "Z_train = np.concatenate([e1_train, e2_train, lag_trn], axis=1)\n",
        "Z_val   = np.concatenate([e1_val,   e2_val,   lag_val], axis=1)\n",
        "Z_test  = np.concatenate([e1_test,  e2_test,  lag_tst], axis=1)\n",
        "print('Hybrid feature shapes:', Z_train.shape, Z_val.shape, Z_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 8) Bayesian Ridge on hybrid features\n",
        "pipe_bayes = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"bayes\", BayesianRidge(compute_score=True))\n",
        "])\n",
        "pipe_bayes.fit(np.vstack([Z_train, Z_val]), np.concatenate([y_train, y_val]))\n",
        "yhat_bayes = pipe_bayes.predict(Z_test)\n",
        "rmse_b = mean_squared_error(y_test, yhat_bayes, squared=False)\n",
        "mae_b  = mean_absolute_error(y_test, yhat_bayes)\n",
        "dir_b  = (np.sign(yhat_bayes) == np.sign(y_test)).mean()\n",
        "print(f\"Bayesian Ridge (hybrid) \u2192 RMSE={rmse_b:.6f}  MAE={mae_b:.6f}  DirAcc={dir_b:.3f}\")\n",
        "\n",
        "joblib.dump(pipe_bayes, os.path.join(ART_DIR, 'bayes_hybrid.joblib'))\n",
        "print('Saved Bayesian Ridge:', os.path.join(ART_DIR, 'bayes_hybrid.joblib'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 9) SARIMAX with exogenous hybrid features (optional but included)\n",
        "# Align exogenous features with target times: our windows end at t, target is y at t+1.\n",
        "exog_full = np.concatenate([e1_train, e2_train, last_k_lags(Xs_train, lag_k)], axis=1)\n",
        "exog_full = np.vstack([exog_full, np.concatenate([e1_val, e2_val, last_k_lags(Xs_val, lag_k)], axis=1)])\n",
        "exog_test = np.concatenate([e1_test, e2_test, last_k_lags(Xs_test, lag_k)], axis=1)\n",
        "\n",
        "# Build pandas index-aligned series for SARIMAX\n",
        "idx_train_full = idx_end_train  # end-of-window dates for train+val\n",
        "idx_test_full  = idx_end_test\n",
        "\n",
        "# Align y's index to next day\n",
        "y_train_full = np.concatenate([y_train, y_val])\n",
        "y_train_idx = idx_train_full + pd.tseries.offsets.BDay(1)\n",
        "y_test_idx  = idx_test_full  + pd.tseries.offsets.BDay(1)\n",
        "y_train_series = pd.Series(y_train_full, index=y_train_idx)\n",
        "y_test_series  = pd.Series(y_test,       index=y_test_idx)\n",
        "\n",
        "# Shift exog so its index matches y index (forecast time)\n",
        "exog_train_df = pd.DataFrame(exog_full, index=idx_train_full)\n",
        "exog_test_df  = pd.DataFrame(exog_test,  index=idx_test_full)\n",
        "exog_train_shift = exog_train_df.copy(); exog_train_shift.index = y_train_idx\n",
        "exog_test_shift  = exog_test_df.copy();  exog_test_shift.index  = y_test_idx\n",
        "\n",
        "# Fit SARIMAX on returns with exogenous features\n",
        "sarimax = SARIMAX(y_train_series, order=(1,0,1), seasonal_order=(0,0,0,0), exog=exog_train_shift,\n",
        "                  enforce_stationarity=False, enforce_invertibility=False)\n",
        "sarimax_res = sarimax.fit(disp=False)\n",
        "fc = sarimax_res.forecast(steps=len(y_test_series), exog=exog_test_shift)\n",
        "rmse_s = mean_squared_error(y_test_series.values, fc.values, squared=False)\n",
        "mae_s  = mean_absolute_error(y_test_series.values, fc.values)\n",
        "dir_s  = (np.sign(fc.values) == np.sign(y_test_series.values)).mean()\n",
        "print(f\"SARIMAX(exog) \u2192 RMSE={rmse_s:.6f}  MAE={mae_s:.6f}  DirAcc={dir_s:.3f}\")\n",
        "\n",
        "with open(os.path.join(ART_DIR, 'sarimax.pkl'), 'wb') as f:\n",
        "    pickle.dump(sarimax_res, f)\n",
        "print('Saved SARIMAX:', os.path.join(ART_DIR, 'sarimax.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 10) Compare model performance and plot test predictions\n",
        "metrics = {\n",
        "    'lstm':   {'rmse': float(rmse_lstm), 'mae': float(mae_lstm), 'dir_acc': float(dir_lstm)},\n",
        "    'transformer': {'rmse': float(rmse_tr), 'mae': float(mae_tr), 'dir_acc': float(dir_tr)},\n",
        "    'bayes_hybrid': {'rmse': float(rmse_b), 'mae': float(mae_b), 'dir_acc': float(dir_b)},\n",
        "    'sarimax_exog': {'rmse': float(rmse_s), 'mae': float(mae_s), 'dir_acc': float(dir_s)}\n",
        "}\n",
        "print(json.dumps(metrics, indent=2))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(y_test_series.index, y_test_series.values, label='Actual')\n",
        "plt.plot(y_test_series.index, yhat_lstm, label='LSTM')\n",
        "plt.plot(y_test_series.index, yhat_tr, label='Transformer')\n",
        "plt.plot(y_test_series.index, yhat_bayes, label='Bayes Hybrid')\n",
        "plt.plot(y_test_series.index, fc.values, label='SARIMAX exog')\n",
        "plt.title(f\"{TARGET_TICKER} \u2014 Test Next-Day Returns (model comparison)\")\n",
        "plt.legend(); plt.xlabel('Date'); plt.ylabel('Return'); plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "source": [
        "#@title 11) Save meta.json\n",
        "meta = {\n",
        "    'target': TARGET_TICKER,\n",
        "    'window': int(WINDOW),\n",
        "    'splits': {\n",
        "        'train_end_index': int(len(Xs_train)-1),\n",
        "        'val_end_index': int(len(Xs_train)+len(Xs_val)-1)\n",
        "    },\n",
        "    'metrics': metrics\n",
        "}\n",
        "with open(os.path.join(ART_DIR, 'meta.json'), 'w') as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "print('Saved meta.json')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}